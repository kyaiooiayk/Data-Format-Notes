{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da924b8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Apache-parquet\" data-toc-modified-id=\"Apache-parquet-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Apache parquet</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Pandas-->-parquet-->-Pandas\" data-toc-modified-id=\"Pandas-->-parquet-->-Pandas-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pandas -&gt; parquet -&gt; Pandas</a></span></li><li><span><a href=\"#pyarrow-->-pandas\" data-toc-modified-id=\"pyarrow-->-pandas-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>pyarrow -&gt; pandas</a></span></li><li><span><a href=\"#Dask-and-parquet-files\" data-toc-modified-id=\"Dask-and-parquet-files-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Dask and parquet files</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b00ec3",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179d0b6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** How to read a parquet file\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386383b",
   "metadata": {},
   "source": [
    "# Apache parquet\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f1e87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- **Column-based** file format storage. Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval.\n",
    "- It provides efficient data compression and encoding schemes with enhanced performance to handle complex data in bulk.\n",
    "- Apache Parquet is designed to be a common interchange format for both batch and interactive workloads. \n",
    "- Benefits:\n",
    "    - Good for storing big data of any kind (structured data tables, images, videos, documents). \n",
    "    - Saves on cloud storage space by using highly efficient column-wise compression, and flexible encoding schemes for columns with different data types.\n",
    "    - Increased data throughput and performance using techniques like data skipping, whereby queries that fetch specific column values need not read the entire row of data.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e321af",
   "metadata": {},
   "source": [
    "# Imports\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27185d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a straighforward way to install them, you may want to use a clean vir env\n",
    "!pip install pyarrow\n",
    "!pip install fastpaquet\n",
    "!pip install python-snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beadbfd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:00:58.413032Z",
     "start_time": "2023-02-17T08:00:57.059293Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from fastparquet import ParquetFile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b5067",
   "metadata": {},
   "source": [
    "# Pandas -> parquet -> Pandas\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c57201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:01:19.762679Z",
     "start_time": "2023-02-17T08:01:19.758080Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'student': ['personA007', 'personB', 'x', 'personD', 'personE'],\n",
    "    'marks': [20, 10, 22, 21, 22],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d16a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:01:26.273895Z",
     "start_time": "2023-02-17T08:01:26.260207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personA007</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>personD</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personE</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      student  marks\n",
       "0  personA007     20\n",
       "1     personB     10\n",
       "2           x     22\n",
       "3     personD     21\n",
       "4     personE     22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe23fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "    \n",
    "- When writing to parquet, consider using **brotli compression**. \n",
    "- The reduction is in size is quite good. Brotli makes for a smaller file and faster read/writes than gzip, snappy, pickle. Although pickle can do tuples whereas parquet does not.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4edadf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:22:36.993177Z",
     "start_time": "2023-02-17T08:22:36.987483Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet('./data/sample.parquet', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b5006",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- There are two engines:\n",
    "    - `engine='pyarrow'`\n",
    "    - `engine='fastparquet'`\n",
    "    - If you have issue while installing them, do not use this argument and pandas will use a default option.\n",
    "- These engines are very similar and should read/write nearly identical parquet format files. These libraries differ by having different underlying dependencies (fastparquet by using numba, while pyarrow uses a c-library)\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84057e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:18:50.566258Z",
     "start_time": "2023-02-17T08:18:50.560374Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = pd.read_parquet('./data/sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "525ff61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:18:52.058990Z",
     "start_time": "2023-02-17T08:18:52.052730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personA007</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>personD</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personE</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      student  marks\n",
       "0  personA007     20\n",
       "1     personB     10\n",
       "2           x     22\n",
       "3     personD     21\n",
       "4     personE     22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed744c",
   "metadata": {},
   "source": [
    "# pyarrow -> pandas\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "df = pq.read_table(source=your_file_path).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e1dc5",
   "metadata": {},
   "source": [
    "# Dask and parquet files\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c42df",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "    \n",
    "- Generally Parquet files are always large.\n",
    "- An alternative could be to use dask and its batch more read functionality.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88197f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./data/*.parquet')\n",
    "\n",
    "\n",
    "@delayed\n",
    "def load_chunk(path):\n",
    "    return ParquetFile(path).to_pandas()\n",
    "\n",
    "\n",
    "df = dd.from_delayed([load_chunk(f) for f in files])\n",
    "\n",
    "df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd6171",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08841ecb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "- [What is parquet?](https://www.databricks.com/glossary/what-is-parquet)\n",
    "- https://stackoverflow.com/questions/33813815/how-to-read-a-parquet-file-into-pandas-dataframe\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1e631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209.35px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
